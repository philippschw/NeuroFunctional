{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFXCAYAAAC/aQfJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx8iqc2AVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f717fe5f490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# D. van den Berg\n",
    "# Source: http://christopher5106.github.io/deep/learning/2015/09/04/Deep-learning-tutorial-on-Caffe-Technology.html\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append('/home/philipp/caffe/caffe-master/python') \n",
    "import caffe\n",
    "\n",
    "# finding the activation values of the last fully connected neuron layer (fc7) for a single image input\n",
    "\n",
    "#Init\n",
    "caffe.set_mode_cpu()\n",
    "\n",
    "#load the model\n",
    "model_path = '/home/philipp/NeuroFunctional-master/models/bvlc_reference_caffenet/'\n",
    "# net_fn   = model_path + '/bck/deploy.prototxt'\n",
    "\n",
    "net_fn = model_path + 'bck/deploy.prototxt'\n",
    "\n",
    "# UnicodeDecodeError\n",
    "# import gzip\n",
    "# fp = gzip.open(model_path + r'caffenet_train_iter_10000.caffemodel.gz')\n",
    "# param_fn = fp.read() # contents now has the uncompressed bytes of foo.gz\n",
    "# fp.close()\n",
    "# param_fn = param_fn.decode('ascii') # u_str is now a unicode string\n",
    "\n",
    "param_fn = model_path+ 'caffenet_train_iter_10000.caffemodel'\n",
    "# param_fn = model_path + 'caffenet_train_iter_45000.caffemodel'\n",
    "\n",
    "net = caffe.Net(net_fn,\n",
    "                param_fn,\n",
    "                caffe.TEST)\n",
    "\n",
    "# load input and configure preprocessing\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer_path ='/home/philipp/NeuroFunctional-master/python/caffe/imagenet/'\n",
    "transformer.set_mean('data', np.load(transformer_path+'ilsvrc_2012_mean.npy').mean(1).mean(1))\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "transformer.set_raw_scale('data', 255.0)\n",
    "\n",
    "#note we can change the batch size on-the-fly\n",
    "#since we classify only one image, we change batch size from 10 to 1\n",
    "net.blobs['data'].reshape(1,3,227,227)\n",
    "\n",
    "#load the image in the data layer\n",
    "image_path = 'AVA/trainingset/preprocesed/'\n",
    "image_name = '203.jpg'\n",
    "im = caffe.io.load_image(image_path+image_name)\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', im)\n",
    "\n",
    "#compute\n",
    "out = net.forward()\n",
    "\n",
    "# other possibility : out = net.forward_all(data=np.asarray([transformer.preprocess('data', im)]))\n",
    "\n",
    "#predicted predicted class\n",
    "print(out['prob'].argmax())\n",
    "\n",
    "#print predicted labels\n",
    "# labels = np.loadtxt(\"/home/philipp/caffe/caffe-master/data/ilsvrc12/synset_words.txt\", str, delimiter='\\t')\n",
    "# top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
    "# print(labels[top_k])\n",
    "\n",
    "#print pre-last layer\n",
    "x = net.blobs['fc7']\n",
    "plt.plot(x.data[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(x.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print 'number of image files: ', len(os.walk('AVA/trainingset/preprocesed').next()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_activation_fc7(image):\n",
    "#load the image in the data layer\n",
    "    im = caffe.io.load_image(image)\n",
    "    net.blobs['data'].data[...] = transformer.preprocess('data', im)\n",
    "    x = net.blobs['fc7']\n",
    "    \n",
    "# other possibility : out = net.forward_all(data=np.asarray([transformer.preprocess('data', im)]))\n",
    "\n",
    "    # return activations of neuron layer and predicted class as label   \n",
    "    return x.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "labels = np.loadtxt(\"/home/philipp/caffe/caffe-master/data/ilsvrc12/synset_words.txt\", str, delimiter='\\t')\n",
    "\n",
    "image_path = \"AVA/trainingset/preprocesed/*.jpg\"\n",
    "\n",
    "nr_images  = len(glob.glob(image_path))\n",
    "\n",
    "my_array = np.zeros((nr_images, 4096)) #np array rows, columns\n",
    "for row_number, image in enumerate(glob.glob(image_path)): #fill an entire row\n",
    "    my_array[row_number:] = get_activation_fc7(image)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_activation_fc7_and_label(image):\n",
    "# #load the image in the data layer\n",
    "#     im = caffe.io.load_image(image)\n",
    "#     net.blobs['data'].data[...] = transformer.preprocess('data', im)\n",
    "#     x = net.blobs['fc7']\n",
    "    \n",
    "#     out = net.forward()\n",
    "\n",
    "# # other possibility : out = net.forward_all(data=np.asarray([transformer.preprocess('data', im)]))\n",
    "\n",
    "#     # return activations of neuron layer and predicted class as label   \n",
    "#     return x.data[0], labels[out['prob'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# labels = np.loadtxt(\"/home/philipp/caffe/caffe-master/data/ilsvrc12/synset_words.txt\", str, delimiter='\\t')\n",
    "\n",
    "# image_path = \"AVA/trainingset/preprocesed/*.jpg\"\n",
    "\n",
    "# nr_images  = len(glob.glob(image_path))\n",
    "\n",
    "# # dict_arrays = dict((x, my_array) for x in labels)\n",
    "\n",
    "# my_array = np.zeros((nr_images, 4096)) #np array rows, columns\n",
    "# for row_number, image in enumerate(glob.glob(image_path)): #fill an entire row\n",
    "#     activations, label     =    get_activation_fc7_and_label(image)  \n",
    "#     if label == 'n04592741 wing':\n",
    "#         print 'Condition True for wing label'\n",
    "#         my_array[row_number:] =     activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[908]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_array[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_array[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Neuron_activation_penultimate_layer/{}.csv\".format(image_name), my_array, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from numpy import genfromtxt\n",
    "my_data = np.genfromtxt(\"Neuron_activation_penultimate_layer/{}.csv\".format(image_name), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata = my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Value Decomposition (SVD)\n",
    "The singular values are the spuare root of the eigenvalues of Data*Data.T \n",
    "\n",
    "In essence, SVD is a data summary method. It extracts important features from data. Because of its ability to reconstruct an original dataset from an compressed dataset, SVD can be used as efficient image compression method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataT = my_data.T\n",
    "P, D, Q = np.linalg.svd(dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataT.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(P), len(D), len(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(P[:,1])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot((np.absolute(P[:,1])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_P = pd.DataFrame(P[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Neuron with max positive activation: ', df_P.idxmax()[0], '    Neuron with max negative activation: ', df_P.idxmin()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eigvals = D**2 / np.cumsum(D)[-1]\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "sing_vals = np.arange(dataT.shape[1]) + 1\n",
    "plt.plot(sing_vals, eigvals, 'ro-', linewidth=2)\n",
    "plt.title('Screeplot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigenvalue')\n",
    "#I don't like the default legend so I typically make mine like below, e.g.\n",
    "#with smaller fonts and a bit transparent so I do not cover up data, and make\n",
    "#it moveable by the viewer in case upper-right is a bad place for it \n",
    "leg = plt.legend(['Eigenvalues from SVD'], loc='best', borderpad=0.3, \n",
    "                 shadow=False, prop=matplotlib.font_manager.FontProperties(size='small'),\n",
    "                 markerscale=0.4)\n",
    "leg.get_frame().set_alpha(0.4)\n",
    "leg.draggable(state=True)\n",
    "plt.xlim([0, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q =  Q * 10000000\n",
    "plt.imshow(Q, interpolation='none', cmap='jet')\n",
    "ax = plt.gca()\n",
    "plt.title(\"$V$\")\n",
    "plt.yscale=('log')\n",
    "plt.xscale=('log')\n",
    "ax.grid(b=False)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
